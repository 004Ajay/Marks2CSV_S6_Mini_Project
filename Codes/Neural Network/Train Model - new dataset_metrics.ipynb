{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e44d236",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3ecbb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the image size and batch size\n",
    "img_size = (40, 40)\n",
    "batch_size = 32\n",
    "\n",
    "# Path to your dataset folder\n",
    "data_dir = \"C:/Users/justi/OneDrive/Desktop/Justin/School/College/S6/S6_Mini_Project/dataset/Mixed_Marks_Dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe5d71a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18135 files belonging to 8 classes.\n",
      "Using 14508 files for training.\n",
      "Found 18135 files belonging to 8 classes.\n",
      "Using 3627 files for validation.\n"
     ]
    }
   ],
   "source": [
    "# use image_dataset_from_directory to load the data and split it into training and testing sets\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset='training',\n",
    "    seed=123,\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size)\n",
    "\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset='validation',\n",
    "    seed=123,\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84d8103c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class names: ['0', '1', '2', '3', '4', '5', '6', '7']\n",
      "Number of classes: 8\n"
     ]
    }
   ],
   "source": [
    "# inspect the class names and number of classes\n",
    "class_names = train_ds.class_names\n",
    "num_classes = len(class_names)\n",
    "print('Class names:', class_names)\n",
    "print('Number of classes:', num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64c036d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\justi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\autograph\\pyct\\static_analysis\\liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    }
   ],
   "source": [
    "# convert images to grayscale\n",
    "def grayscale(image, label):\n",
    "    image = tf.image.rgb_to_grayscale(image)\n",
    "    return image, label\n",
    "\n",
    "train_ds = train_ds.map(grayscale)\n",
    "val_ds = val_ds.map(grayscale)\n",
    "\n",
    "# normalize pixel values to be between 0 and 1\n",
    "train_ds = train_ds.map(lambda x, y: (x / 255.0, y))\n",
    "val_ds = val_ds.map(lambda x, y: (x / 255.0, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56ff5c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the neural network\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(16, 3, activation='relu', input_shape=(40, 40, 1)),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# The neural network architecture consists of sequential layers, where the output of one layer is passed as input to the next layer.\n",
    "\n",
    "# The first layer is a convolutional layer with 16 filters of size 3x3, followed by a ReLU activation function. \n",
    "# The input shape of the layer is (40, 40, 1), which means that the layer expects input images of size 40x40 with one color channel (grayscale).\n",
    "\n",
    "# The second layer is a max pooling layer that reduces the spatial dimensions of the output from the previous layer by taking the maximum value in each 2x2 window.\n",
    "\n",
    "# The third layer is another convolutional layer with 32 filters of size 3x3, followed by a ReLU activation function.\n",
    "\n",
    "# The fourth layer is another max pooling layer.\n",
    "\n",
    "# The fifth layer is a flatten layer that flattens the output from the previous layer into a 1D vector.\n",
    "\n",
    "# The sixth layer is a dense layer with 64 units and a ReLU activation function.\n",
    "\n",
    "# The seventh and final layer is a dense layer with num_classes units and a softmax activation function, which produces the predicted class probabilities for the input image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "71b27730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "# For visualizing the model\n",
    "\n",
    "from keras.utils.vis_utils import plot_model\n",
    "plot_model(model, \n",
    "           to_file='model.png',\n",
    "           show_shapes=True,\n",
    "           show_dtype=False,\n",
    "           show_layer_names=True,\n",
    "           rankdir='TB',\n",
    "           expand_nested=False,\n",
    "           dpi=300,\n",
    "           layer_range=None,\n",
    "           show_layer_activations=True\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d46fed79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ann_visualizer.visualize import ann_viz;\n",
    "\n",
    "# ann_viz(model, title=\"My first neural network\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "458c1918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88caabd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\justi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\backend.py:5585: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "454/454 [==============================] - 17s 35ms/step - loss: 1.1268 - accuracy: 0.6245 - val_loss: 0.5714 - val_accuracy: 0.8307\n",
      "Epoch 2/10\n",
      "454/454 [==============================] - 14s 30ms/step - loss: 0.3685 - accuracy: 0.8890 - val_loss: 0.2722 - val_accuracy: 0.9209\n",
      "Epoch 3/10\n",
      "454/454 [==============================] - 15s 32ms/step - loss: 0.2175 - accuracy: 0.9359 - val_loss: 0.2106 - val_accuracy: 0.9391\n",
      "Epoch 4/10\n",
      "454/454 [==============================] - 15s 33ms/step - loss: 0.1558 - accuracy: 0.9540 - val_loss: 0.1636 - val_accuracy: 0.9526\n",
      "Epoch 5/10\n",
      "454/454 [==============================] - 14s 29ms/step - loss: 0.1119 - accuracy: 0.9703 - val_loss: 0.1394 - val_accuracy: 0.9625\n",
      "Epoch 6/10\n",
      "454/454 [==============================] - 16s 35ms/step - loss: 0.0850 - accuracy: 0.9753 - val_loss: 0.1403 - val_accuracy: 0.9584\n",
      "Epoch 7/10\n",
      "454/454 [==============================] - 14s 31ms/step - loss: 0.0625 - accuracy: 0.9826 - val_loss: 0.1385 - val_accuracy: 0.9595\n",
      "Epoch 8/10\n",
      "454/454 [==============================] - 14s 31ms/step - loss: 0.0505 - accuracy: 0.9858 - val_loss: 0.1295 - val_accuracy: 0.9633\n",
      "Epoch 9/10\n",
      "454/454 [==============================] - 17s 36ms/step - loss: 0.0377 - accuracy: 0.9891 - val_loss: 0.1316 - val_accuracy: 0.9622\n",
      "Epoch 10/10\n",
      "454/454 [==============================] - 14s 30ms/step - loss: 0.0280 - accuracy: 0.9927 - val_loss: 0.1245 - val_accuracy: 0.9633\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x29220e55cf0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model\n",
    "model.fit(train_ds, validation_data=val_ds, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8174140e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 96.33%\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(val_ds, verbose=0)\n",
    "\n",
    "print(f'Testing accuracy: {(accuracy*100):.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b80ba357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 38, 38, 16)        160       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 19, 19, 16)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 17, 17, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 8, 8, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                131136    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 520       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 136,456\n",
      "Trainable params: 136,456\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fbaec046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('MP.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02ffcc38",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "confusion_matrix() missing 1 required positional argument: 'y_pred'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m confusion_matrix\n\u001b[1;32m----> 3\u001b[0m cm \u001b[38;5;241m=\u001b[39m \u001b[43mconfusion_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_ds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(cm)\n",
      "\u001b[1;31mTypeError\u001b[0m: confusion_matrix() missing 1 required positional argument: 'y_pred'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(val_ds)\n",
    "\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0a83e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
