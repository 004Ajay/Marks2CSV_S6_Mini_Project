{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fb00c77",
   "metadata": {},
   "source": [
    "# Click to go to respective testing heading\n",
    "\n",
    "<a href = \"# Testing with 0 to 7\" >  fast 0 to 7 Test </a>\n",
    "\n",
    "\n",
    "<a href = \"#Total-Number-of-Images-in-each-folder\" >Total number of images in each folder</a>\n",
    "\n",
    "<a href = \"#All-Accuracies\" >All accuracies</a>\n",
    "\n",
    "<a href = \"#Ground-Truth-&-Classification-Result\" >Ground truth and classification result</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64d2ff1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17e528ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"MP_None_Set.h5\") # loading our pre-trained model\n",
    "\n",
    "# Change path to dataset here â†“\n",
    "img_dirs = [f\"C:/Users/ASUS/Desktop/testing2/{i}\" for i in range(9)]\n",
    "img_dir_0, img_dir_1, img_dir_2, img_dir_3, img_dir_4, img_dir_5, img_dir_6, img_dir_7, img_dir_8 = img_dirs\n",
    "\n",
    "# Declaring images in each folder and their ground truth as a list  \n",
    "image_list_0, image_list_1, image_list_2, image_list_3, image_list_4, image_list_5, image_list_6, image_list_7, image_list_8 = [os.listdir(dir) for dir in img_dirs]\n",
    "\n",
    "gnd_trt_0, gnd_trt_1, gnd_trt_2, gnd_trt_3, gnd_trt_4, gnd_trt_5, gnd_trt_6, gnd_trt_7, gnd_trt_8 = [i for i in range(9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641879fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(image_folder, image_list):\n",
    "    pred = []\n",
    "\n",
    "    # Loop through all the images in the folder and classify them\n",
    "    for image_name in image_list:\n",
    "    \n",
    "        test_image = tf.keras.preprocessing.image.load_img(os.path.join(image_folder, image_name), target_size=(40, 40), color_mode='grayscale')\n",
    "        test_image = np.expand_dims(test_image, axis=0) # Expand the dimensions of the image to match the input shape of the model\n",
    "    \n",
    "        result = model.predict(test_image)\n",
    "    \n",
    "        predicted_value = np.argmax(result[0])\n",
    "    \n",
    "        pred.append(predicted_value)\n",
    "        \n",
    "#         pred = ['None' if x == 8 else x for x in pred]\n",
    "        \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5aaa6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(gnd_trt, image_list, preds): # Accuracy calculation\n",
    "    true_labels = [gnd_trt] * len(image_list)\n",
    "    correct_predictions = sum(preds[i] == true_labels[i] for i in range(len(image_list)))\n",
    "    accuracy_percent = (correct_predictions / len(true_labels)) * 100\n",
    "    return accuracy_percent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e1cabd",
   "metadata": {},
   "source": [
    "# Testing with 0 to 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5192704",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_0 = prediction(img_dir_0, image_list_0)\n",
    "preds_1 = prediction(img_dir_1, image_list_1)\n",
    "preds_2 = prediction(img_dir_2, image_list_2)\n",
    "preds_3 = prediction(img_dir_3, image_list_3)\n",
    "preds_4 = prediction(img_dir_4, image_list_4)\n",
    "preds_5 = prediction(img_dir_5, image_list_5)\n",
    "preds_6 = prediction(img_dir_6, image_list_6)\n",
    "preds_7 = prediction(img_dir_7, image_list_7)\n",
    "preds_8 = prediction(img_dir_8, image_list_8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db5d743",
   "metadata": {},
   "source": [
    "## Total Number of Images in each folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1e4197",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(9): # Hard coded, as we know the no of classes\n",
    "    print(f\"Total images in {i} : {len(locals()[f'image_list_{i}'])}\")\n",
    "    # locals() method returns a dictionary with all the local variables for the current program."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a16c9c0",
   "metadata": {},
   "source": [
    "## All Accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce44475f",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc=[\n",
    "accuracy(gnd_trt_0, image_list_0, preds_0),\n",
    "accuracy(gnd_trt_1, image_list_1, preds_1),\n",
    "accuracy(gnd_trt_2, image_list_2, preds_2),\n",
    "accuracy(gnd_trt_3, image_list_3, preds_3),\n",
    "accuracy(gnd_trt_4, image_list_4, preds_4),\n",
    "accuracy(gnd_trt_5, image_list_5, preds_5),\n",
    "accuracy(gnd_trt_6, image_list_6, preds_6),\n",
    "accuracy(gnd_trt_7, image_list_7, preds_7),\n",
    "accuracy(gnd_trt_8, image_list_8, preds_8),\n",
    "]\n",
    "    \n",
    "import matplotlib.pyplot as plt    \n",
    "\n",
    "labels = [f'{i}' for i in range(9)]\n",
    "labels[8] = 'None'\n",
    "fig, ax = plt.subplots(figsize=(8,4))\n",
    "ax.barh(labels, acc, align='center')\n",
    "\n",
    "# Add axis labels and title\n",
    "ax.set_xlabel('Accuracy')\n",
    "ax.set_ylabel('Class')\n",
    "ax.set_title('Accuracy by Class')\n",
    "\n",
    "ax.invert_yaxis() # Invert y-axis to list classes from top to bottom\n",
    "\n",
    "for i, acc in enumerate(acc):\n",
    "    ax.text(acc -11, i, f'{acc:.2f}%', va='center',weight='bold',color='white')\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6a2cbf",
   "metadata": {},
   "source": [
    "## Ground Truth & Classification Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f048373",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(9):\n",
    "    print(f\"Ground Truth: {locals()[f'gnd_trt_{i}']}\\n\\nClassified Values:\\n{locals()[f'preds_{i}']}\\n\\n--------------------------------------------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae89c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Initialize empty prediction arrays\n",
    "pd = [[] for _ in range(9)]\n",
    "\n",
    "# Loop over the classes\n",
    "for i in range(9):\n",
    "    # Get the length of the predictions for the current class\n",
    "    pred_len = len(locals()[f'preds_{i}'])\n",
    "    # Loop over the predictions and append the class label to the pd array\n",
    "    for j in range(pred_len):\n",
    "        pd[i].append(i)\n",
    "    # Print the pd array and the corresponding ground truth for debugging\n",
    "    print(pd[i])\n",
    "    # print(locals()[f'preds_{i}'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac53ed9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.concatenate([pd[i] for i in range(9)])\n",
    "y_pred = np.concatenate([preds_0,preds_1,preds_2,preds_3,preds_4,preds_5,preds_6,preds_7,preds_8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeab30b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "class_names = ['0', '1', '2', '3', '4', '5', '6', '7', 'None']\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "fig = disp.ax_.get_figure() \n",
    "fig.set_figwidth(8)\n",
    "fig.set_figheight(8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0a1b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3345b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
